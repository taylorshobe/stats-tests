{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "import pandasql as psql\n",
    "from pandasql import sqldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-67b859071fbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;31m# Perform the T-Tests and get the results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m \u001b[0mt_test_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperform_t_tests\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_test_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the function to perform T-Tests and calculate Cohen's d\n",
    "def perform_t_tests(df, metrics, alpha=0.05):\n",
    "    # Get unique values for 'area' and 'tenured'\n",
    "    areas = df['area'].unique()\n",
    "    tenured_statuses = df['tenured'].unique()\n",
    "    \n",
    "    # Function to interpret Cohen's d\n",
    "    def interpret_cohen_d(d):\n",
    "        if abs(d) < 0.2:\n",
    "            return \"Small\"\n",
    "        elif abs(d) < 0.5:\n",
    "            return \"Medium\"\n",
    "        else:\n",
    "            return \"Large\"\n",
    "\n",
    "    # Initialize a list to store results\n",
    "    results = []\n",
    "\n",
    "    for tenured in tenured_statuses:\n",
    "        for area in areas:\n",
    "            for metric in metrics:\n",
    "                # Subset data based on 'area' and 'tenured'\n",
    "                subset = df[(df['tenured'] == tenured) & (df['area'] == area)]\n",
    "                # Separate data into 'HOME' and 'OFFICE' groups\n",
    "                wfh_data = subset[subset['day_type'] == 'HOME'][metric]\n",
    "                office_data = subset[subset['day_type'] == 'OFFICE'][metric]\n",
    "                \n",
    "                if len(wfh_data) > 0 and len(office_data) > 0:\n",
    "                    # Perform T-Test\n",
    "                    t_stat, p_value = ttest_ind(wfh_data, office_data, equal_var=False, nan_policy='omit')\n",
    "                    \n",
    "                    # Calculate means and sample sizes\n",
    "                    wfh_mean = wfh_data.mean()\n",
    "                    office_mean = office_data.mean()\n",
    "                    wfh_std = wfh_data.std()\n",
    "                    office_std = office_data.std()\n",
    "                    n_wfh = len(wfh_data)\n",
    "                    n_office = len(office_data)\n",
    "                    \n",
    "                    # Calculate pooled standard deviation\n",
    "                    pooled_std = np.sqrt(((n_wfh - 1) * wfh_std**2 + (n_office - 1) * office_std**2) / (n_wfh + n_office - 2))\n",
    "                    \n",
    "                    # Calculate Cohen's d\n",
    "                    cohen_d = (wfh_mean - office_mean) / pooled_std\n",
    "                    cohen_d_interpretation = interpret_cohen_d(cohen_d)\n",
    "                    \n",
    "                    # Append results to the list\n",
    "                    results.append({\n",
    "                        'Tenured': tenured,\n",
    "                        'Area': area,\n",
    "                        'Metric': metric,\n",
    "                        'WFH Mean': wfh_mean,\n",
    "                        'Office Mean': office_mean,\n",
    "                        'T-Statistic': t_stat,\n",
    "                        'P-Value': round(p_value, 5),\n",
    "                        'Cohen D': round(cohen_d, 5),\n",
    "                        'Cohen D Interpretation': cohen_d_interpretation\n",
    "                    })\n",
    "        \n",
    "        # Add combined area for the current tenured status\n",
    "        for metric in metrics:\n",
    "            combined_subset = df[df['tenured'] == tenured]\n",
    "            wfh_data_combined = combined_subset[combined_subset['day_type'] == 'HOME'][metric]\n",
    "            office_data_combined = combined_subset[combined_subset['day_type'] == 'OFFICE'][metric]\n",
    "            \n",
    "            if len(wfh_data_combined) > 0 and len(office_data_combined) > 0:\n",
    "                # Perform T-Test\n",
    "                t_stat_combined, p_value_combined = ttest_ind(wfh_data_combined, office_data_combined, equal_var=False, nan_policy='omit')\n",
    "                \n",
    "                # Calculate means and sample sizes\n",
    "                wfh_mean_combined = wfh_data_combined.mean()\n",
    "                office_mean_combined = office_data_combined.mean()\n",
    "                wfh_std_combined = wfh_data_combined.std()\n",
    "                office_std_combined = office_data_combined.std()\n",
    "                n_wfh_combined = len(wfh_data_combined)\n",
    "                n_office_combined = len(office_data_combined)\n",
    "                \n",
    "                # Calculate pooled standard deviation\n",
    "                pooled_std_combined = np.sqrt(((n_wfh_combined - 1) * wfh_std_combined**2 + (n_office_combined - 1) * office_std_combined**2) / (n_wfh_combined + n_office_combined - 2))\n",
    "                \n",
    "                # Calculate Cohen's d\n",
    "                cohen_d_combined = (wfh_mean_combined - office_mean_combined) / pooled_std_combined\n",
    "                cohen_d_combined_interpretation = interpret_cohen_d(cohen_d_combined)\n",
    "                \n",
    "                # Append combined area results to the list\n",
    "                results.append({\n",
    "                    'Tenured': tenured,\n",
    "                    'Area': 'All Areas Combined',\n",
    "                    'Metric': metric,\n",
    "                    'WFH Mean': wfh_mean_combined,\n",
    "                    'Office Mean': office_mean_combined,\n",
    "                    'T-Statistic': t_stat_combined,\n",
    "                    'P-Value': round(p_value_combined, 5),\n",
    "                    'Cohen D': round(cohen_d_combined, 5),\n",
    "                    'Cohen D Interpretation': cohen_d_combined_interpretation\n",
    "                })\n",
    "    \n",
    "    # Convert results list to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "# Assuming 'result_df' is your DataFrame loaded with your data\n",
    "metrics = ['avg_interaction_count', 'aht', 'avg_productivity']\n",
    "\n",
    "# Set the alpha level (e.g., 0.05 for a 95% confidence level)\n",
    "alpha = 0.05\n",
    "\n",
    "# Perform the T-Tests and get the results\n",
    "t_test_results = perform_t_tests(result_df, metrics)\n",
    "\n",
    "print(t_test_results.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from math import asin, sqrt\n",
    "\n",
    "# Transcribe the data into a list of dictionaries\n",
    "data = [\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Chat\", \"Sample\": 4, \"Metric\": \"Adherence\", \"WFH Proportion\": 0.755},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Chat\", \"Sample\": 4, \"Metric\": \"Consults\", \"WFH Proportion\": 0.153},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Chat\", \"Sample\": 4, \"Metric\": \"OSAT\", \"WFH Proportion\": 0.552},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Chat\", \"Sample\": 4, \"Metric\": \"Transfers\", \"WFH Proportion\": 0.129},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Client Banking Services\", \"Sample\": 46, \"Metric\": \"Adherence\", \"WFH Proportion\": 0.912},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Client Banking Services\", \"Sample\": 46, \"Metric\": \"Consults\", \"WFH Proportion\": 0.206},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Client Banking Services\", \"Sample\": 46, \"Metric\": \"OSAT\", \"WFH Proportion\": 0.472},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Client Banking Services\", \"Sample\": 46, \"Metric\": \"Transfers\", \"WFH Proportion\": 0.148},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Core Service\", \"Sample\": 594, \"Metric\": \"Adherence\", \"WFH Proportion\": 0.836},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Core Service\", \"Sample\": 594, \"Metric\": \"Consults\", \"WFH Proportion\": 0.178},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Core Service\", \"Sample\": 594, \"Metric\": \"OSAT\", \"WFH Proportion\": 0.468},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Core Service\", \"Sample\": 594, \"Metric\": \"Transfers\", \"WFH Proportion\": 0.188},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Tier 2 Support\", \"Sample\": 5, \"Metric\": \"Adherence\", \"WFH Proportion\": 0.888},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Tier 2 Support\", \"Sample\": 5, \"Metric\": \"Consults\", \"WFH Proportion\": 0.104},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Tier 2 Support\", \"Sample\": 5, \"Metric\": \"OSAT\", \"WFH Proportion\": 1.000},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Tier 2 Support\", \"Sample\": 5, \"Metric\": \"Transfers\", \"WFH Proportion\": 0.241},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Trader Service\", \"Sample\": 6, \"Metric\": \"Adherence\", \"WFH Proportion\": 0.822},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Trader Service\", \"Sample\": 6, \"Metric\": \"Consults\", \"WFH Proportion\": 0.266},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Trader Service\", \"Sample\": 6, \"Metric\": \"OSAT\", \"WFH Proportion\": 0.571},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Trader Service\", \"Sample\": 6, \"Metric\": \"Transfers\", \"WFH Proportion\": 0.273},\n",
    "]\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Adding some hypothetical Office Proportion data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "df[\"Office Proportion\"] = np.random.rand(len(df))\n",
    "\n",
    "# Set the alpha level (e.g., 0.05 for a 95% confidence level)\n",
    "alpha = 0.05\n",
    "\n",
    "# Function to interpret Cohen's h\n",
    "def interpret_cohen_h(h):\n",
    "    if abs(h) < 0.2:\n",
    "        return \"Small\"\n",
    "    elif abs(h) < 0.5:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Large\"\n",
    "\n",
    "# Perform Z-tests for each row\n",
    "results = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    count = np.array([row[\"WFH Proportion\"] * row[\"Sample\"], row[\"Office Proportion\"] * row[\"Sample\"]])\n",
    "    nobs = np.array([row[\"Sample\"], row[\"Sample\"]])\n",
    "    \n",
    "    z_score, p_value = proportions_ztest(count, nobs)\n",
    "    \n",
    "    # Calculate Cohen's h\n",
    "    cohen_h = 2 * (asin(sqrt(row[\"WFH Proportion\"])) - asin(sqrt(row[\"Office Proportion\"])))\n",
    "    \n",
    "    results.append({\n",
    "        \"Tenured\": row[\"Tenured\"],\n",
    "        \"Area Name\": row[\"Area Name\"],\n",
    "        \"Sample\": row[\"Sample\"],\n",
    "        \"Metric\": row[\"Metric\"],\n",
    "        \"WFH Proportion\": row[\"WFH Proportion\"],\n",
    "        \"Office Proportion\": row[\"Office Proportion\"],\n",
    "        \"Z-Statistic\": z_score,\n",
    "        \"P-Value\": p_value,\n",
    "        \"Cohen H\": cohen_h,\n",
    "        \"Cohen H Interpretation\": interpret_cohen_h(cohen_h),\n",
    "        \"Significant\": p_value < alpha  # Check if the p-value is less than the alpha level\n",
    "    })\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Add combined area for each tenured status\n",
    "combined_results = []\n",
    "\n",
    "for tenured in df['Tenured'].unique():\n",
    "    for metric in df['Metric'].unique():\n",
    "        combined_subset = df[(df['Tenured'] == tenured) & (df['Metric'] == metric)]\n",
    "        combined_sample = combined_subset['Sample'].sum()\n",
    "        combined_wfh_proportion = (combined_subset['WFH Proportion'] * combined_subset['Sample']).sum() / combined_sample\n",
    "        combined_office_proportion = (combined_subset['Office Proportion'] * combined_subset['Sample']).sum() / combined_sample\n",
    "        \n",
    "        count_combined = np.array([combined_wfh_proportion * combined_sample, combined_office_proportion * combined_sample])\n",
    "        nobs_combined = np.array([combined_sample, combined_sample])\n",
    "        \n",
    "        z_score_combined, p_value_combined = proportions_ztest(count_combined, nobs_combined)\n",
    "        \n",
    "        # Calculate Cohen's h for combined data\n",
    "        cohen_h_combined = 2 * (asin(sqrt(combined_wfh_proportion)) - asin(sqrt(combined_office_proportion)))\n",
    "        \n",
    "        combined_results.append({\n",
    "            \"Tenured\": tenured,\n",
    "            \"Area Name\": \"COMBINED\",\n",
    "            \"Sample\": combined_sample,\n",
    "            \"Metric\": metric,\n",
    "            \"WFH Proportion\": combined_wfh_proportion,\n",
    "            \"Office Proportion\": combined_office_proportion,\n",
    "            \"Z-Statistic\": z_score_combined,\n",
    "            \"P-Value\": p_value_combined,\n",
    "            \"Cohen H\": cohen_h_combined,\n",
    "            \"Cohen H Interpretation\": interpret_cohen_h(cohen_h_combined),\n",
    "            \"Significant\": p_value_combined < alpha  # Check if the p-value is less than the alpha level\n",
    "        })\n",
    "\n",
    "# Convert combined results to a DataFrame and append to the original results\n",
    "df_combined_results = pd.DataFrame(combined_results)\n",
    "df_final_results = pd.concat([df_results, df_combined_results], ignore_index=True)\n",
    "\n",
    "# Reorder the columns\n",
    "df_final_results = df_final_results[[\"Tenured\", \"Area Name\", \"Sample\", \"Metric\", \"WFH Proportion\", \"Office Proportion\", \"Z-Statistic\", \"P-Value\", \"Cohen H Interpretation\", \"Significant\"]]\n",
    "\n",
    "print(df_final_results.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-db1c0faefc95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    112\u001b[0m }\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m \u001b[0marea_tenure_z_test_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marea_tenure_z_tests\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[0mcombined_z_test_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombined_z_tests\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result_df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from math import asin, sqrt\n",
    "\n",
    "# Define WFH and Office days\n",
    "wfh_days = ['Tuesday', 'Friday']\n",
    "office_days = ['Monday', 'Wednesday', 'Thursday']\n",
    "\n",
    "# Function to interpret Cohen's h\n",
    "def interpret_cohen_h(h):\n",
    "    if abs(h) < 0.2:\n",
    "        return \"Small\"\n",
    "    elif abs(h) < 0.5:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Large\"\n",
    "\n",
    "# Function to get the overall difference in proportions by area and tenure\n",
    "def area_tenure_z_tests(df, metrics_dict):\n",
    "    area_names = df['area_name'].unique()\n",
    "    tenured_statuses = df['tenured'].unique()\n",
    "    results = []\n",
    "\n",
    "    for tenured in tenured_statuses:\n",
    "        for area in area_names:\n",
    "            for metric, (num_col, den_col) in metrics_dict.items():\n",
    "                subset = df[(df['tenured'] == tenured) & (df['area_name'] == area)]\n",
    "                wfh_subset = subset[subset['day'].isin(wfh_days)]\n",
    "                office_subset = subset[subset['day'].isin(office_days)]\n",
    "                wfh_numerator = wfh_subset[num_col].sum()\n",
    "                wfh_denominator = wfh_subset[den_col].sum()\n",
    "                office_numerator = office_subset[num_col].sum()\n",
    "                office_denominator = office_subset[den_col].sum()\n",
    "\n",
    "                if wfh_denominator == 0 or office_denominator == 0:\n",
    "                    continue\n",
    "\n",
    "                count = np.array([wfh_numerator, office_numerator])\n",
    "                observations = np.array([wfh_denominator, office_denominator])\n",
    "                z_stat, p_value = proportions_ztest(count, observations)\n",
    "                wfh_proportion = wfh_numerator / wfh_denominator if wfh_denominator else None\n",
    "                office_proportion = office_numerator / office_denominator if office_denominator else None\n",
    "\n",
    "                # Calculate Cohen's h\n",
    "                cohen_h = 2 * (asin(sqrt(wfh_proportion)) - asin(sqrt(office_proportion)))\n",
    "                cohen_h_interpretation = interpret_cohen_h(cohen_h)\n",
    "\n",
    "                results.append({\n",
    "                    'Tenured': tenured,\n",
    "                    'Area Name': area,\n",
    "                    'Metric': metric,\n",
    "                    'WFH Proportion': wfh_proportion,\n",
    "                    'Office Proportion': office_proportion,\n",
    "                    'Z-Statistic': z_stat,\n",
    "                    'P-Value': p_value.round(5),\n",
    "                    'Cohen H': round(cohen_h, 5),\n",
    "                    'Cohen H Interpretation': cohen_h_interpretation\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Function to get the overall difference in proportions by tenure (area agnostic)\n",
    "def combined_z_tests(df, metrics_dict):\n",
    "    tenured_statuses = df['tenured'].unique()\n",
    "    results = []\n",
    "\n",
    "    for tenured in tenured_statuses:\n",
    "        for metric, (num_col, den_col) in metrics_dict.items():\n",
    "            subset = df[df['tenured'] == tenured]\n",
    "            wfh_subset = subset[subset['day'].isin(wfh_days)]\n",
    "            office_subset = subset[subset['day'].isin(office_days)]\n",
    "            wfh_numerator = wfh_subset[num_col].sum()\n",
    "            wfh_denominator = wfh_subset[den_col].sum()\n",
    "            office_numerator = office_subset[num_col].sum()\n",
    "            office_denominator = office_subset[den_col].sum()\n",
    "\n",
    "            if wfh_denominator == 0 or office_denominator == 0:\n",
    "                continue\n",
    "\n",
    "            count = np.array([wfh_numerator, office_numerator])\n",
    "            observations = np.array([wfh_denominator, office_denominator])\n",
    "            z_stat, p_value = proportions_ztest(count, observations)\n",
    "            wfh_proportion = wfh_numerator / wfh_denominator if wfh_denominator else None\n",
    "            office_proportion = office_numerator / office_denominator if office_denominator else None\n",
    "\n",
    "            # Calculate Cohen's h\n",
    "            cohen_h = 2 * (asin(sqrt(wfh_proportion)) - asin(sqrt(office_proportion)))\n",
    "            cohen_h_interpretation = interpret_cohen_h(cohen_h)\n",
    "\n",
    "            results.append({\n",
    "                'Tenured': tenured,\n",
    "                'Area Name': \"COMBINED\",\n",
    "                'Metric': metric,\n",
    "                'WFH Proportion': wfh_proportion,\n",
    "                'Office Proportion': office_proportion,\n",
    "                'Z-Statistic': z_stat,\n",
    "                'P-Value': p_value.round(5),\n",
    "                'Cohen H': round(cohen_h, 5),\n",
    "                'Cohen H Interpretation': cohen_h_interpretation\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Test\n",
    "\n",
    "metrics_dict = {\n",
    "    'Adherence': ('adh_num', 'adh_den'),\n",
    "    'OSAT': ('top_box', 'osat_count'),\n",
    "    'Transfers': ('transfers', 'interaction_count'),\n",
    "    'Consults': ('consults', 'interaction_count')\n",
    "}\n",
    "\n",
    "area_tenure_z_test_df = area_tenure_z_tests(result_df, metrics_dict)\n",
    "combined_z_test_df = combined_z_tests(result_df, metrics_dict)\n",
    "\n",
    "z_test = pd.concat([area_tenure_z_test_df, combined_z_test_df])\n",
    "\n",
    "print(z_test.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   day_type        date person_id       area_name tenured  talk_time  \\\n",
      "0    OFFICE  2024-01-03   A003083  High Net Worth     Yes       2353   \n",
      "1    OFFICE  2024-01-03   A003091            Chat     Yes      34945   \n",
      "2    OFFICE  2024-01-03   A003434  High Net Worth     Yes       6693   \n",
      "3    OFFICE  2024-01-03   A003687  Trader Service     Yes      12467   \n",
      "4    OFFICE  2024-01-03   A003771  High Net Worth     Yes       6444   \n",
      "5      HOME  2024-01-03   A004173    Core Service     Yes      18897   \n",
      "6      HOME  2024-01-03   A004173    Core Service     Yes      18897   \n",
      "7      HOME  2024-01-03   A004432  Trader Service     Yes      11115   \n",
      "8      HOME  2024-01-03   A005648  Trader Service     Yes       7036   \n",
      "9      HOME  2024-01-03   A007225            Chat     Yes      13667   \n",
      "10   OFFICE  2024-01-03   A008689  High Net Worth     Yes       3786   \n",
      "11     HOME  2024-01-03   A009607    Core Service     Yes      12718   \n",
      "12   OFFICE  2024-01-03   A009687    Core Service     Yes      13221   \n",
      "13     HOME  2024-01-03   A015864  High Net Worth     Yes       2695   \n",
      "14   OFFICE  2024-01-03   A017412    Core Service     Yes       2200   \n",
      "\n",
      "    wrap_time  interaction_count  total_head_ct  tenure_head_ct  \\\n",
      "0         749                  9           2468            1840   \n",
      "1           0                 51           2468            1840   \n",
      "2        1402                 12           2468            1840   \n",
      "3        4207                 26           2468            1840   \n",
      "4          84                  7           2468            1840   \n",
      "5        3399                 33           2468            1840   \n",
      "6        3399                 33           2468            1840   \n",
      "7        1736                 14           2468            1840   \n",
      "8        4361                 22           2468            1840   \n",
      "9           0                 18           2468            1840   \n",
      "10         27                 10           2468            1840   \n",
      "11       2010                 15           2468            1840   \n",
      "12        663                 18           2468            1840   \n",
      "13         27                  9           2468            1840   \n",
      "14        749                  4           2468            1840   \n",
      "\n",
      "    area_tenure_head_ct  \n",
      "0                   241  \n",
      "1                   209  \n",
      "2                   241  \n",
      "3                   326  \n",
      "4                   241  \n",
      "5                   764  \n",
      "6                   764  \n",
      "7                   326  \n",
      "8                   326  \n",
      "9                   209  \n",
      "10                  241  \n",
      "11                  764  \n",
      "12                  764  \n",
      "13                  241  \n",
      "14                  764  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data for the DataFrame\n",
    "data = {\n",
    "    'day_type': [\n",
    "        'OFFICE', 'OFFICE', 'OFFICE', 'OFFICE', 'OFFICE',\n",
    "        'HOME', 'HOME', 'HOME', 'HOME', 'HOME',\n",
    "        'OFFICE', 'HOME', 'OFFICE', 'HOME', 'OFFICE'\n",
    "    ],\n",
    "    'date': [\n",
    "        '2024-01-03', '2024-01-03', '2024-01-03', '2024-01-03', '2024-01-03', \n",
    "        '2024-01-03', '2024-01-03', '2024-01-03', '2024-01-03', '2024-01-03', \n",
    "        '2024-01-03', '2024-01-03', '2024-01-03', '2024-01-03', '2024-01-03'\n",
    "    ],\n",
    "    'person_id': [\n",
    "        'A003083', 'A003091', 'A003434', 'A003687', 'A003771', \n",
    "        'A004173', 'A004173', 'A004432', 'A005648', 'A007225', \n",
    "        'A008689', 'A009607', 'A009687', 'A015864', 'A017412'\n",
    "    ],\n",
    "    'area_name': [\n",
    "        'High Net Worth', 'Chat', 'High Net Worth', 'Trader Service', 'High Net Worth', \n",
    "        'Core Service', 'Core Service', 'Trader Service', 'Trader Service', 'Chat', \n",
    "        'High Net Worth', 'Core Service', 'Core Service', 'High Net Worth', 'Core Service'\n",
    "    ],\n",
    "    'tenured': ['Yes'] * 15,\n",
    "    'talk_time': [\n",
    "        2353, 34945, 6693, 12467, 6444, \n",
    "        18897, 18897, 11115, 7036, 13667, \n",
    "        3786, 12718, 13221, 2695, 2200\n",
    "    ],\n",
    "    'wrap_time': [\n",
    "        749, 0, 1402, 4207, 84, \n",
    "        3399, 3399, 1736, 4361, 0, \n",
    "        27, 2010, 663, 27, 749\n",
    "    ],\n",
    "    'interaction_count': [\n",
    "        9, 51, 12, 26, 7, \n",
    "        33, 33, 14, 22, 18, \n",
    "        10, 15, 18, 9, 4\n",
    "    ],\n",
    "    'total_head_ct': [\n",
    "        2468, 2468, 2468, 2468, 2468, \n",
    "        2468, 2468, 2468, 2468, 2468, \n",
    "        2468, 2468, 2468, 2468, 2468\n",
    "    ],\n",
    "    'tenure_head_ct': [\n",
    "        1840, 1840, 1840, 1840, 1840, \n",
    "        1840, 1840, 1840, 1840, 1840, \n",
    "        1840, 1840, 1840, 1840, 1840\n",
    "    ],\n",
    "    'area_tenure_head_ct': [\n",
    "        241, 209, 241, 326, 241, \n",
    "        764, 764, 326, 326, 209, \n",
    "        241, 764, 764, 241, 764\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "result_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   day_type       area_name   tenured  sample       aht\n",
      "0      HOME        COMBINED  COMBINED    2468  694.1458\n",
      "1      HOME        COMBINED       Yes    1840  694.1458\n",
      "2      HOME            Chat       Yes     209  759.2778\n",
      "3      HOME    Core Service       Yes     764  732.3457\n",
      "4      HOME  High Net Worth       Yes     241  302.4444\n",
      "5      HOME  Trader Service       Yes     326  673.5556\n",
      "6    OFFICE        COMBINED  COMBINED    2468  656.8613\n",
      "7    OFFICE        COMBINED       Yes    1840  656.8613\n",
      "8    OFFICE            Chat       Yes     209  685.1961\n",
      "9    OFFICE    Core Service       Yes     764  765.1364\n",
      "10   OFFICE  High Net Worth       Yes     241  566.7895\n",
      "11   OFFICE  Trader Service       Yes     326  641.3077\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "  day_type\n",
    ", area_name\n",
    ", tenured\n",
    ", area_tenure_head_ct AS sample\n",
    ", ROUND(CAST(SUM(talk_time + wrap_time) AS FLOAT) / SUM(interaction_count), 4) AS aht\n",
    "FROM result_df\n",
    "WHERE interaction_count > 0\n",
    "GROUP BY 1, 2, 3, 4\n",
    "\n",
    "UNION\n",
    "\n",
    "SELECT \n",
    "  day_type\n",
    ", \"COMBINED\" AS area_name\n",
    ", tenured\n",
    ", tenure_head_ct AS sample\n",
    ", ROUND(CAST(SUM(talk_time + wrap_time) AS FLOAT) / SUM(interaction_count), 4) AS aht\n",
    "FROM result_df\n",
    "WHERE interaction_count > 0\n",
    "GROUP BY 1, 2, 3, 4\n",
    "\n",
    "\n",
    "UNION\n",
    "\n",
    "SELECT \n",
    "  day_type\n",
    ", \"COMBINED\" AS area_name\n",
    ", \"COMBINED\" AS tenured\n",
    ", total_head_ct AS sample\n",
    ", ROUND(CAST(SUM(talk_time + wrap_time) AS FLOAT) / SUM(interaction_count), 4) AS aht\n",
    "FROM result_df\n",
    "WHERE interaction_count > 0\n",
    "GROUP BY 1, 2, 3, 4\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "aht_df = sqldf(query)\n",
    "print(aht_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tenured       Area_Name    WFH Mean  Office Mean  T-Statistic  P-Value  \\\n",
      "0       Yes  High Net Worth  302.444444   566.789474          NaN      NaN   \n",
      "1       Yes            Chat  759.277778   685.196078          NaN      NaN   \n",
      "2       Yes  Trader Service  673.555556   641.307692          NaN      NaN   \n",
      "3       Yes    Core Service  732.345679   765.136364          NaN      NaN   \n",
      "4       Yes        COMBINED         NaN          NaN          NaN      NaN   \n",
      "5        No        COMBINED         NaN          NaN          NaN      NaN   \n",
      "6  COMBINED        COMBINED         NaN          NaN          NaN      NaN   \n",
      "\n",
      "   Effect Size  \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2          NaN  \n",
      "3          NaN  \n",
      "4          NaN  \n",
      "5          NaN  \n",
      "6          NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tshob\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\fromnumeric.py:3622: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n",
      "C:\\Users\\tshob\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\tshob\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:234: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate Cohen's d\n",
    "def cohen_d(x, y):\n",
    "    return (np.mean(x) - np.mean(y)) / np.sqrt((np.std(x, ddof=1) ** 2 + np.std(y, ddof=1) ** 2) / 2)\n",
    "\n",
    "# Function to calculate aht\n",
    "def calculate_aht(group):\n",
    "    return (group['talk_time'] + group['wrap_time']).sum() / group['interaction_count'].sum()\n",
    "\n",
    "# Function to perform the t-test\n",
    "def ttest_wfh_vs_office(df, area_name, tenured):\n",
    "    wfh = df[(df['day_type'] == 'HOME') & (df['area_name'] == area_name) & (df['tenured'] == tenured)]\n",
    "    office = df[(df['day_type'] == 'OFFICE') & (df['area_name'] == area_name) & (df['tenured'] == tenured)]\n",
    "    \n",
    "    if len(wfh) > 0 and len(office) > 0:\n",
    "        wfh_aht = calculate_aht(wfh)\n",
    "        office_aht = calculate_aht(office)\n",
    "        \n",
    "        t_stat, p_value = ttest_ind(wfh_aht, office_aht, equal_var=False)\n",
    "        effect_size = cohen_d(wfh_aht, office_aht)\n",
    "        \n",
    "        return [tenured, area_name, wfh_aht, office_aht, t_stat, p_value, effect_size]\n",
    "    else:\n",
    "        return [tenured, area_name, None, None, None, None, None]\n",
    "\n",
    "# List to hold the results\n",
    "results = []\n",
    "\n",
    "# Unique area names and tenured status\n",
    "area_names = result_df['area_name'].unique()\n",
    "tenured_statuses = result_df['tenured'].unique()\n",
    "\n",
    "# Perform t-tests for each area_name and tenured status\n",
    "for area_name in area_names:\n",
    "    for tenured in tenured_statuses:\n",
    "        results.append(ttest_wfh_vs_office(result_df, area_name, tenured))\n",
    "\n",
    "# Add combination cases\n",
    "results.append(ttest_wfh_vs_office(result_df, \"COMBINED\", \"Yes\"))\n",
    "results.append(ttest_wfh_vs_office(result_df, \"COMBINED\", \"No\"))\n",
    "results.append(ttest_wfh_vs_office(result_df, \"COMBINED\", \"COMBINED\"))\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "output_columns = [\"Tenured\", \"Area_Name\", \"WFH Mean\", \"Office Mean\", \"T-Statistic\", \"P-Value\", \"Effect Size\"]\n",
    "results_df = pd.DataFrame(results, columns=output_columns)\n",
    "\n",
    "# Display the results\n",
    "print(results_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mynewenv",
   "language": "python",
   "name": "mynewenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
